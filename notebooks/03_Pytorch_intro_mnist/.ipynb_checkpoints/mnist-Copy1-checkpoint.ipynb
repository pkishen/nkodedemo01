{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch with NoKode\n",
    "\n",
    "In this notebook we will walk through training a character recongition model using the MNIST dataset on Pytorch. \n",
    "We will then show you how to use Kubeflow Fairing to run the same training job on both Kubeflow and CMLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "torch\n",
    "torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 1)) (0.18.2)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 2)) (8.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#you can skip this step if you have already installed the necessary dependencies\n",
    "!pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "# For mac users you may get hit with this bug https://github.com/pytorch/pytorch/issues/20030\n",
    "# temporary solution is \"brew install libomp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Model Defintion\n",
    "\n",
    "Setup a Convolution Nueral network using Pytorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py -a\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Training and Test Functions\n",
    "A simple training function that batches the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py -a\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0 and batch_idx>0:\n",
    "            print('Train Epoch: {}\\t[{}/{}\\t({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "              100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py -a\n",
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(\n",
    "              output, target, size_average=False).item()  # sum up batch loss\n",
    "            pred = output.max(\n",
    "              1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          test_loss, correct, len(test_loader.dataset),\n",
    "          100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile train_model.py -a\n",
    "def nkTrain(batch_size=64, epochs=1, log_interval=100, lr=0.01, model_dir=None, momentum=0.5, \n",
    "                       no_cuda=False, seed=1, test_batch_size=1000):\n",
    "\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    print(\"Using {} for training.\".format(device))\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST(\n",
    "          'data',\n",
    "          train=True,\n",
    "          download=True,\n",
    "          transform=transforms.Compose([\n",
    "              transforms.ToTensor(),\n",
    "              # Normalize a tensor image with mean and standard deviation\n",
    "              transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "          ])),\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "      datasets.MNIST(\n",
    "          'data',\n",
    "          train=False,\n",
    "          transform=transforms.Compose([\n",
    "              transforms.ToTensor(),\n",
    "              # Normalize a tensor image with mean and standard deviation              \n",
    "              transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "          ])),\n",
    "      batch_size=test_batch_size,\n",
    "      shuffle=True,\n",
    "      **kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "        print(\"Time taken for epoch #{}: {:.2f}s\".format(epoch, time.time()-start_time))\n",
    "        test(model, device, test_loader, epoch)\n",
    "\n",
    "    if model_dir:\n",
    "        model_file_name = 'torch.model'\n",
    "        tmp_model_file = os.path.join('/tmp', model_file_name)\n",
    "        torch.save(model.state_dict(), tmp_model_file)\n",
    "        subprocess.check_call([\n",
    "            'gsutil', 'cp', tmp_model_file,\n",
    "            os.path.join(model_dir, model_file_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Check Local Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 2\n",
      "Memory: 7.5006561279296875\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def local_resources():\n",
    "    print(\"CPU count: {}\".format(multiprocessing.cpu_count()))\n",
    "    print(\"Memory: {}\".format(os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')/(1024.**3)))\n",
    "\n",
    "local_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for training.\n",
      "Train Epoch: 1\t[6400/60000\t(11%)]\tLoss: 1.929761\n",
      "Train Epoch: 1\t[12800/60000\t(21%)]\tLoss: 1.327502\n",
      "Train Epoch: 1\t[19200/60000\t(32%)]\tLoss: 0.846595\n",
      "Train Epoch: 1\t[25600/60000\t(43%)]\tLoss: 0.674760\n",
      "Train Epoch: 1\t[32000/60000\t(53%)]\tLoss: 0.442683\n",
      "Train Epoch: 1\t[38400/60000\t(64%)]\tLoss: 0.704966\n",
      "Train Epoch: 1\t[44800/60000\t(75%)]\tLoss: 0.470975\n",
      "Train Epoch: 1\t[51200/60000\t(85%)]\tLoss: 0.810192\n",
      "Train Epoch: 1\t[57600/60000\t(96%)]\tLoss: 0.412998\n",
      "Time taken for epoch #1: 19.63s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2063, Accuracy: 9387/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nkTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Docker Images and train using the container.\n",
    "\n",
    "In this block we set some Docker config. Fairing will use this information to package up the `train_and_test` function i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello auto from create image\n",
      "sh /usr/lib/node_modules/nkode/scripts/remoteTrain/remote_train.sh  auto data/MNIST tensorflow/tensorflow:1.15.0-py3  nkTrain\n",
      "auto data/MNIST tensorflow/tensorflow:1.15.0-py3 nkTrain\n",
      "[I 201027 07:04:47 utils:320] IMDS ENDPOINT: http://169.254.169.254/\n",
      "[W 201027 07:04:47 function:49] The FunctionPreProcessor is optimized for using in a notebook or IPython environment. For it to work, the python version should be same for both local python and the python in the docker. Please look at alternatives like BasePreprocessor or FullNotebookPreprocessor.\n",
      "[W 201027 07:04:47 tasks:62] Using builder: <class 'kubeflow.fairing.builders.cluster.cluster.ClusterBuilder'>\n",
      "[I 201027 07:04:47 tasks:66] Building the docker image.\n",
      "[I 201027 07:04:47 cluster:46] Building image using cluster builder.\n",
      "[W 201027 07:04:47 base:94] /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "[I 201027 07:04:47 base:107] Creating docker context: /tmp/fairing_context_121eg27i\n",
      "[W 201027 07:04:47 base:94] /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "[W 201027 07:04:47 aws:70] Not able to find aws credentials secret: aws-secret\n",
      "[W 201027 07:04:47 manager:298] Waiting for fairing-builder-fjz6m-n95s9 to start...\n",
      "[W 201027 07:04:47 manager:298] Waiting for fairing-builder-fjz6m-n95s9 to start...\n",
      "[W 201027 07:04:47 manager:298] Waiting for fairing-builder-fjz6m-n95s9 to start...\n",
      "[I 201027 07:04:51 manager:304] Pod started running True\n",
      "[W 201027 07:08:21 aws:70] Not able to find aws credentials secret: aws-secret\n",
      "[W 201027 07:08:21 job:101] The job fairing-job-c956d launched.\n",
      "[W 201027 07:08:21 manager:298] Waiting for fairing-job-c956d-tmt9p to start...\n",
      "[W 201027 07:08:21 manager:298] Waiting for fairing-job-c956d-tmt9p to start...\n",
      "[W 201027 07:08:21 manager:298] Waiting for fairing-job-c956d-tmt9p to start...\n",
      "[I 201027 07:08:58 manager:304] Pod started running True\n",
      "Namespace(baseImage='tensorflow/tensorflow:1.15.0-py3', dataDir='data/MNIST', entryPoint='nkTrain', method='auto')\n",
      "About to train job setup...\n",
      "ENTRY POINT for building image is :nkTrain\n",
      "Now in FUNCTION  or CLASS entrypoint. Entry point is set as nkTrain\n",
      "about to submit job\n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0002] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0002] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0002] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0003] Executing 0 build triggers\n",
      "\u001b[36mINFO\u001b[0m[0003] Unpacking rootfs as cmd COPY /app//requirements.txt /app/ requires it.\n",
      "\u001b[36mINFO\u001b[0m[0036] WORKDIR /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] cmd: workdir\n",
      "\u001b[36mINFO\u001b[0m[0036] Changed working directory to /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Creating directory /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0036] ENV FAIRING_RUNTIME 1\n",
      "\u001b[36mINFO\u001b[0m[0036] COPY /app//requirements.txt /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0036] RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0038] Resolving 27381 paths\n",
      "\u001b[36mINFO\u001b[0m[0043] cmd: /bin/sh\n",
      "\u001b[36mINFO\u001b[0m[0043] args: [-c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "\u001b[36mINFO\u001b[0m[0043] Running: [/bin/sh -c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "Collecting torch\n",
      "  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
      "Collecting torchvision\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/dc/4a939cfbd38398f4765f712576df21425241020bfccc200af76d19088533/torchvision-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (5.9MB)\n",
      "Collecting future\n",
      "  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r requirements.txt (line 2)) (1.17.3)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=493275 sha256=80e2e71575bfc7f368cd36b7abad3cdff939a0985214168d540c07709d903ba5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-79j05zvr/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built future\n",
      "Installing collected packages: future, torch, pillow, torchvision\n",
      "Successfully installed future-0.18.2 pillow-8.0.1 torch-1.6.0 torchvision-0.7.0\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0070] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0077] Resolving 32300 paths\n",
      "\u001b[36mINFO\u001b[0m[0115] COPY /app/ /app/\n",
      "\u001b[36mINFO\u001b[0m[0115] Resolving 13 paths\n",
      "\u001b[36mINFO\u001b[0m[0115] Taking snapshot of files...\n",
      "Using cpu for training.\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "Train Epoch: 1\t[6400/60000\t(11%)]\tLoss: 1.929761\n",
      "Train Epoch: 1\t[12800/60000\t(21%)]\tLoss: 1.327502\n",
      "Train Epoch: 1\t[19200/60000\t(32%)]\tLoss: 0.846595\n",
      "Train Epoch: 1\t[25600/60000\t(43%)]\tLoss: 0.674760\n",
      "Train Epoch: 1\t[32000/60000\t(53%)]\tLoss: 0.442683\n",
      "Train Epoch: 1\t[38400/60000\t(64%)]\tLoss: 0.704966\n",
      "Train Epoch: 1\t[44800/60000\t(75%)]\tLoss: 0.470975\n",
      "Train Epoch: 1\t[51200/60000\t(85%)]\tLoss: 0.810192\n",
      "Train Epoch: 1\t[57600/60000\t(96%)]\tLoss: 0.412998\n",
      "Time taken for epoch #1: 18.73s\n",
      "\n",
      "Test set: Average loss: 0.2063, Accuracy: 9387/10000 (94%)\n",
      "\n",
      "15.7%\n",
      "29.8%\n",
      "43.9%\n",
      "58.0%[W 201027 07:09:23 job:173] Cleaning up job fairing-job-c956d...\n",
      "\n",
      "72.1%\n",
      "86.2%\n",
      "56.4%%\n",
      "85.5%%\n",
      "180.4%/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Job to create image  is :  fairing-job-c956d\n",
      "Successfully created Docker Image in the configured registry 340489779538.dkr.ecr.us-west-2.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "!nkode create:image -d \"data/MNIST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN on Additional resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 201027 07:20:32 tasks:62] Using builder: <class 'kubeflow.fairing.builders.cluster.cluster.ClusterBuilder'>\n",
      "[I 201027 07:20:32 tasks:66] Building the docker image.\n",
      "[I 201027 07:20:32 cluster:46] Building image using cluster builder.\n",
      "[W 201027 07:20:32 base:94] /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "[I 201027 07:20:32 base:107] Creating docker context: /tmp/fairing_context_if2sgrso\n",
      "[W 201027 07:20:32 base:94] /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "[W 201027 07:20:32 aws:70] Not able to find aws credentials secret: aws-secret\n",
      "[W 201027 07:20:32 manager:298] Waiting for fairing-builder-ttghx-vzj9g to start...\n",
      "[W 201027 07:20:32 manager:298] Waiting for fairing-builder-ttghx-vzj9g to start...\n",
      "[W 201027 07:24:20 manager:298] Waiting for fairing-builder-ttghx-vzj9g to start...\n",
      "[W 201027 07:24:20 manager:298] Waiting for fairing-builder-ttghx-vzj9g to start...\n"
     ]
    }
   ],
   "source": [
    "import random, string\n",
    "import os\n",
    "import subprocess\n",
    "import importlib\n",
    "from kubeflow import fairing\n",
    "from kubeflow.fairing import TrainJob\n",
    "from kubeflow.fairing.backends import KubeflowAWSBackend\n",
    "from kubeflow.fairing.kubernetes.utils import get_resource_mutator\n",
    "\n",
    "\n",
    "FAIRING_BACKEND = 'KubeflowAWSBackend'\n",
    "AWS_ACCOUNT_ID=fairing.cloud.aws.guess_account_id()\n",
    "AWS_REGION='us-west-2'\n",
    "DOCKER_REGISTRY = '{}.dkr.ecr.{}.amazonaws.com'.format(AWS_ACCOUNT_ID, AWS_REGION)\n",
    "PY_VERSION = \".\".join([str(x) for x in sys.version_info[0:3]])\n",
    "#BASE_IMAGE = '{}/python:{}'.format(DOCKER_REGISTRY, PY_VERSION)\n",
    "# TODO: bug to fix. use tensorflow image temporarily\n",
    "#BASE_IMAGE = 'tensorflow/tensorflow:1.15.0-py3'\n",
    "BASE_DOCKER_IMAGE = 'python:3.6.9'\n",
    "DATASET ='data/MNIST'\n",
    "REQUIREMENTS = 'requirements.txt'\n",
    "S3_BUCKET = 'pjz16s-eks-ml-data'\n",
    "\n",
    "\n",
    "if FAIRING_BACKEND == 'KubeflowAWSBackend':\n",
    "    from kubeflow.fairing.builders.cluster.s3_context import S3ContextSource\n",
    "    BuildContext = S3ContextSource(\n",
    "        aws_account=AWS_ACCOUNT_ID, region=AWS_REGION,\n",
    "        bucket_name=S3_BUCKET\n",
    "    )\n",
    "\n",
    "BackendClass = getattr(importlib.import_module('kubeflow.fairing.backends'), FAIRING_BACKEND)\n",
    "\n",
    "train_job = TrainJob(nkTrain, input_files=[DATASET,REQUIREMENTS],\n",
    "                     base_docker_image=BASE_DOCKER_IMAGE,\n",
    "                     docker_registry=DOCKER_REGISTRY,\n",
    "                     backend=BackendClass(build_context_source=BuildContext),\n",
    "                     pod_spec_mutators=[get_resource_mutator(cpu=1, memory=1)])\n",
    "\n",
    "train_job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
