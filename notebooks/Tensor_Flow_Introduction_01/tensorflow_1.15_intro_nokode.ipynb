{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Fairing Introduction\n",
    "\n",
    "Kubeflow Fairing is a Python package that streamlines the process of `building`, `training`, and `deploying` machine learning (ML) models in a hybrid cloud environment. By using Kubeflow Fairing and adding a few lines of code, you can run your ML training job locally or in the cloud, directly from Python code or a Jupyter notebook. After your training job is complete, you can use Kubeflow Fairing to deploy your trained model as a prediction endpoint.\n",
    "\n",
    "\n",
    "# How does Kubeflow Fairing work\n",
    "\n",
    "Kubeflow Fairing \n",
    "1. Packages your Jupyter notebook, Python function, or Python file as a Docker image\n",
    "2. Deploys and runs the training job on Kubeflow or AI Platform. \n",
    "3. Deploy your trained model as a prediction endpoint on Kubeflow after your training job is complete.\n",
    "\n",
    "\n",
    "# Goals of Kubeflow Fairing project\n",
    "\n",
    "- Easily package ML training jobs: Enable ML practitioners to easily package their ML model training code, and their codeâ€™s dependencies, as a Docker image.\n",
    "- Easily train ML models in a hybrid cloud environment: Provide a high-level API for training ML models to make it easy to run training jobs in the cloud, without needing to understand the underlying infrastructure.\n",
    "- Streamline the process of deploying a trained model: Make it easy for ML practitioners to deploy trained ML models to a hybrid cloud environment.\n",
    "\n",
    "\n",
    "> Note: Before fairing workshop, please read `README.md` under `02_01_fairing_introduction`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check fairing is installed \n",
    "!pip show kubeflow-fairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example\n",
    "\n",
    "If you see any issues, please restart notebook. It's probably because of new installed packages.\n",
    "\n",
    "Click `Kernel` -> `Restart & Clear Output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_model.py\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def nkTrain():\n",
    "    # Genrating random linear data \n",
    "    # There will be 50 data points ranging from 0 to 50 \n",
    "    x = np.linspace(0, 50, 50) \n",
    "    y = np.linspace(0, 50, 50) \n",
    "\n",
    "    # Adding noise to the random linear data \n",
    "    x += np.random.uniform(-4, 4, 50) \n",
    "    y += np.random.uniform(-4, 4, 50) \n",
    "\n",
    "    n = len(x) # Number of data points \n",
    "\n",
    "    X = tf.placeholder(\"float\") \n",
    "    Y = tf.placeholder(\"float\")\n",
    "    W = tf.Variable(np.random.randn(), name = \"W\") \n",
    "    b = tf.Variable(np.random.randn(), name = \"b\") \n",
    "    learning_rate = 0.01\n",
    "    training_epochs = 1000\n",
    "    \n",
    "    # Hypothesis \n",
    "    y_pred = tf.add(tf.multiply(X, W), b) \n",
    "\n",
    "    # Mean Squared Error Cost Function \n",
    "    cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)\n",
    "\n",
    "    # Gradient Descent Optimizer \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) \n",
    "\n",
    "    # Global Variables Initializer \n",
    "    init = tf.global_variables_initializer() \n",
    "\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(init) \n",
    "      \n",
    "    # Iterating through all the epochs \n",
    "    for epoch in range(training_epochs): \n",
    "          \n",
    "        # Feeding each data point into the optimizer using Feed Dictionary \n",
    "        for (_x, _y) in zip(x, y): \n",
    "            sess.run(optimizer, feed_dict = {X : _x, Y : _y}) \n",
    "          \n",
    "        # Displaying the result after every 50 epochs \n",
    "        if (epoch + 1) % 50 == 0: \n",
    "            # Calculating the cost a every epoch \n",
    "            c = sess.run(cost, feed_dict = {X : x, Y : y}) \n",
    "            print(\"Epoch\", (epoch + 1), \": cost =\", c, \"W =\", sess.run(W), \"b =\", sess.run(b)) \n",
    "      \n",
    "    # Storing necessary values to be used outside the Session \n",
    "    training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) \n",
    "    weight = sess.run(W) \n",
    "    bias = sess.run(b) \n",
    "\n",
    "    print('Weight: ', weight, 'Bias: ', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training for development\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nkTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote training\n",
    "\n",
    "We will show you how to remotely run training job in kubernetes cluster. You can use `ECR` as your container image registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to train job setup...\n",
      "\u001b[33m[W 201019 21:51:02 function:49]\u001b[m The FunctionPreProcessor is optimized for using in a notebook or IPython environment. For it to work, the python version should be same for both local python and the python in the docker. Please look at alternatives like BasePreprocessor or FullNotebookPreprocessor.\n",
      "\u001b[33m[W 201019 21:51:02 tasks:62]\u001b[m Using builder: <class 'kubeflow.fairing.builders.cluster.cluster.ClusterBuilder'>\n",
      "about to submit job\n",
      "\u001b[32m[I 201019 21:51:02 tasks:66]\u001b[m Building the docker image.\n",
      "\u001b[32m[I 201019 21:51:02 cluster:46]\u001b[m Building image using cluster builder.\n",
      "\u001b[33m[W 201019 21:51:02 base:94]\u001b[m /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "\u001b[32m[I 201019 21:51:02 base:107]\u001b[m Creating docker context: /tmp/fairing_context_0xvema0v\n",
      "\u001b[33m[W 201019 21:51:02 base:94]\u001b[m /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "\u001b[33m[W 201019 21:51:03 aws:70]\u001b[m Not able to find aws credentials secret: aws-secret\n",
      "\u001b[33m[W 201019 21:51:03 manager:298]\u001b[m Waiting for fairing-builder-gmz2x-m6wrf to start...\n",
      "\u001b[33m[W 201019 21:51:03 manager:298]\u001b[m Waiting for fairing-builder-gmz2x-m6wrf to start...\n",
      "\u001b[33m[W 201019 21:51:03 manager:298]\u001b[m Waiting for fairing-builder-gmz2x-m6wrf to start...\n",
      "\u001b[32m[I 201019 21:51:05 manager:304]\u001b[m Pod started running True\n",
      "\u001b[36mINFO\u001b[0m[0005] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0006] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0006] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0006] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0007] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0008] Executing 0 build triggers\n",
      "\u001b[36mINFO\u001b[0m[0008] Unpacking rootfs as cmd COPY /app//requirements.txt /app/ requires it.\n",
      "\u001b[36mINFO\u001b[0m[0042] WORKDIR /app/\n",
      "\u001b[36mINFO\u001b[0m[0042] cmd: workdir\n",
      "\u001b[36mINFO\u001b[0m[0042] Changed working directory to /app/\n",
      "\u001b[36mINFO\u001b[0m[0042] Creating directory /app/\n",
      "\u001b[36mINFO\u001b[0m[0042] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0042] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0042] ENV FAIRING_RUNTIME 1\n",
      "\u001b[36mINFO\u001b[0m[0042] COPY /app//requirements.txt /app/\n",
      "\u001b[36mINFO\u001b[0m[0042] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0042] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0042] RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0042] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0044] Resolving 27381 paths\n",
      "\u001b[36mINFO\u001b[0m[0048] cmd: /bin/sh\n",
      "\u001b[36mINFO\u001b[0m[0048] args: [-c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "\u001b[36mINFO\u001b[0m[0048] Running: [/bin/sh -c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.17.3)\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0049] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0049] Resolving 27381 paths\n",
      "\u001b[36mINFO\u001b[0m[0051] COPY /app/ /app/\n",
      "\u001b[36mINFO\u001b[0m[0051] Resolving 13 paths\n",
      "\u001b[36mINFO\u001b[0m[0051] Taking snapshot of files...\n",
      "\u001b[33m[W 201019 21:51:57 aws:70]\u001b[m Not able to find aws credentials secret: aws-secret\n",
      "\u001b[33m[W 201019 21:51:57 job:101]\u001b[m The job fairing-job-84nnq launched.\n",
      "\u001b[33m[W 201019 21:51:57 manager:298]\u001b[m Waiting for fairing-job-84nnq-lxnvn to start...\n",
      "\u001b[33m[W 201019 21:51:57 manager:298]\u001b[m Waiting for fairing-job-84nnq-lxnvn to start...\n",
      "\u001b[33m[W 201019 21:51:57 manager:298]\u001b[m Waiting for fairing-job-84nnq-lxnvn to start...\n",
      "\u001b[32m[I 201019 21:51:59 manager:304]\u001b[m Pod started running True\n",
      "From remote_train_currentrun.py:18: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "From remote_train_currentrun.py:32: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "From remote_train_currentrun.py:35: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "From remote_train_currentrun.py:38: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-10-19 21:52:03.557559: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-10-19 21:52:03.562113: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-10-19 21:52:03.562292: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fairing-job-84nnq-lxnvn): /proc/driver/nvidia/version does not exist\n",
      "2020-10-19 21:52:03.563595: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2020-10-19 21:52:03.607566: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\n",
      "2020-10-19 21:52:03.608830: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4149080 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-19 21:52:03.608857: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Epoch 50 : cost = 4.2347136 W = 0.99920917 b = -0.7337921\n",
      "Epoch 100 : cost = 4.1944256 W = 0.9969737 b = -0.62186074\n",
      "Epoch 150 : cost = 4.161989 W = 0.9949723 b = -0.5216491\n",
      "Epoch 200 : cost = 4.135863 W = 0.9931806 b = -0.43193215\n",
      "Epoch 250 : cost = 4.114807 W = 0.99157643 b = -0.35160986\n",
      "Epoch 300 : cost = 4.097828 W = 0.9901403 b = -0.27969953\n",
      "Epoch 350 : cost = 4.084126 W = 0.9888545 b = -0.21531935\n",
      "Epoch 400 : cost = 4.073062 W = 0.98770344 b = -0.15768039\n",
      "Epoch 450 : cost = 4.0641203 W = 0.98667276 b = -0.10607757\n",
      "Epoch 500 : cost = 4.056888 W = 0.98575014 b = -0.059878483\n",
      "Epoch 550 : cost = 4.051031 W = 0.98492414 b = -0.018517088\n",
      "Epoch 600 : cost = 4.046284 W = 0.98418456 b = 0.018513056\n",
      "Epoch 650 : cost = 4.0424314 W = 0.9835225 b = 0.051665466\n",
      "Epoch 700 : cost = 4.0393014 W = 0.98292977 b = 0.08134615\n",
      "Epoch 750 : cost = 4.036756 W = 0.982399 b = 0.10791873\n",
      "Epoch 800 : cost = 4.034681 W = 0.9819239 b = 0.13170892\n",
      "Epoch 850 : cost = 4.032987 W = 0.98149854 b = 0.15300761\n",
      "Epoch 900 : cost = 4.031602 W = 0.9811177 b = 0.17207623\n",
      "Epoch 950 : cost = 4.0304675 W = 0.9807768 b = 0.18914789\n",
      "Epoch 1000 : cost = 4.029537 W = 0.9804715 b = 0.20443182\n",
      "Weight:  0.9804715 Bias:  0.20443182\n",
      "\u001b[33m[W 201019 21:52:18 job:173]\u001b[m Cleaning up job fairing-job-84nnq...\n"
     ]
    }
   ],
   "source": [
    "!sh ~/nkodedemo01/nkode/remote_train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Deployment\n",
    "\n",
    "This will deploy a remote end to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/nkodedemo01/notebooks/Tensor_Flow_Introduction_01/\n",
      "About to deploy to end point...\n",
      "\u001b[33m[W 201019 21:54:04 function:49]\u001b[m The FunctionPreProcessor is optimized for using in a notebook or IPython environment. For it to work, the python version should be same for both local python and the python in the docker. Please look at alternatives like BasePreprocessor or FullNotebookPreprocessor.\n",
      "\u001b[33m[W 201019 21:54:04 tasks:62]\u001b[m Using builder: <class 'kubeflow.fairing.builders.cluster.cluster.ClusterBuilder'>\n",
      "\u001b[32m[I 201019 21:54:04 tasks:66]\u001b[m Building the docker image.\n",
      "\u001b[32m[I 201019 21:54:04 cluster:46]\u001b[m Building image using cluster builder.\n",
      "\u001b[33m[W 201019 21:54:04 base:94]\u001b[m /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "\u001b[32m[I 201019 21:54:04 base:107]\u001b[m Creating docker context: /tmp/fairing_context_wqv17550\n",
      "\u001b[33m[W 201019 21:54:04 base:94]\u001b[m /usr/local/lib/python3.6/dist-packages/kubeflow/fairing/__init__.py already exists in Fairing context, skipping...\n",
      "\u001b[33m[W 201019 21:54:04 aws:70]\u001b[m Not able to find aws credentials secret: aws-secret\n",
      "\u001b[33m[W 201019 21:54:04 manager:298]\u001b[m Waiting for fairing-builder-7g4j4-tz2gz to start...\n",
      "\u001b[33m[W 201019 21:54:04 manager:298]\u001b[m Waiting for fairing-builder-7g4j4-tz2gz to start...\n",
      "\u001b[33m[W 201019 21:54:04 manager:298]\u001b[m Waiting for fairing-builder-7g4j4-tz2gz to start...\n",
      "\u001b[32m[I 201019 21:54:06 manager:304]\u001b[m Pod started running True\n",
      "\u001b[36mINFO\u001b[0m[0000] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0001] Built cross stage deps: map[]\n",
      "\u001b[36mINFO\u001b[0m[0001] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0002] Retrieving image manifest tensorflow/tensorflow:1.15.0-py3\n",
      "\u001b[36mINFO\u001b[0m[0003] Executing 0 build triggers\n",
      "\u001b[36mINFO\u001b[0m[0003] Unpacking rootfs as cmd COPY /app//requirements.txt /app/ requires it.\n",
      "\u001b[36mINFO\u001b[0m[0036] WORKDIR /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] cmd: workdir\n",
      "\u001b[36mINFO\u001b[0m[0036] Changed working directory to /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Creating directory /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0036] ENV FAIRING_RUNTIME 1\n",
      "\u001b[36mINFO\u001b[0m[0036] COPY /app//requirements.txt /app/\n",
      "\u001b[36mINFO\u001b[0m[0036] Resolving 1 paths\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of files...\n",
      "\u001b[36mINFO\u001b[0m[0036] RUN if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi\n",
      "\u001b[36mINFO\u001b[0m[0036] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0041] Resolving 27381 paths\n",
      "\u001b[36mINFO\u001b[0m[0044] cmd: /bin/sh\n",
      "\u001b[36mINFO\u001b[0m[0044] args: [-c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "\u001b[36mINFO\u001b[0m[0044] Running: [/bin/sh -c if [ -e requirements.txt ];then pip install --no-cache -r requirements.txt; fi]\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.17.3)\n",
      "WARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\u001b[36mINFO\u001b[0m[0045] Taking snapshot of full filesystem...\n",
      "\u001b[36mINFO\u001b[0m[0045] Resolving 27381 paths\n",
      "\u001b[36mINFO\u001b[0m[0048] COPY /app/ /app/\n",
      "\u001b[36mINFO\u001b[0m[0048] Resolving 13 paths\n",
      "\u001b[36mINFO\u001b[0m[0048] Taking snapshot of files...\n",
      "\u001b[32m[I 201019 21:54:55 tasks:100]\u001b[m Deploying the endpoint.\n",
      "\u001b[32m[I 201019 21:54:55 serving:74]\u001b[m Cluster endpoint: http://fairing-service-p2qsx.eksworkshop.svc.cluster.local:5000/predict\n",
      "\u001b[33m[W 201019 21:54:55 tasks:106]\u001b[m Prediction endpoint: http://fairing-service-p2qsx.eksworkshop.svc.cluster.local:5000/predict\n"
     ]
    }
   ],
   "source": [
    "!sh ~/nkodedemo01/nkode/remote_deploy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: try 'curl --help' or 'curl --manual' for more information\r\n"
     ]
    }
   ],
   "source": [
    "!curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (56) Recv failure: Connection reset by peer\r\n"
     ]
    }
   ],
   "source": [
    "!curl http://fairing-service-p2qsx.eksworkshop.svc.cluster.local:5000/predict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
